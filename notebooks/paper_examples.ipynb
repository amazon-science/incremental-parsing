{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import ast\n",
    "import random\n",
    "\n",
    "from ansi.colour import bg, fg\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "from incremental_parsing.evaluation.text_cuts import cut_text_random\n",
    "from incremental_parsing.generation.constrained_generation import unconstrained_generation, \\\n",
    "    prefix_suffix_constrained_generation, do_prefix_suffix_constrained_generation\n",
    "from incremental_parsing.generation.utils import tokenizer_int64, create_balanced_context\n",
    "from incremental_parsing.lex_earley.lark_grammar import get_python_context\n",
    "import datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:23:52.736902Z",
     "start_time": "2023-08-21T16:23:51.022261Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:23:52.764923Z",
     "start_time": "2023-08-21T16:23:52.739995Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "BEAM_SIZE = 1\n",
    "MAX_GENERATION_LENGTH = 250"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:23:52.784276Z",
     "start_time": "2023-08-21T16:23:52.764779Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/home/ec2-user/.cache/huggingface/datasets/bigcode___json/bigcode--the-stack-smol-xl-1fe14832da3eae85/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dfce8b1da46440feacfdbf662816e24d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"bigcode/santacoder\"\n",
    "DEVICE = \"cuda:0\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, trust_remote_code=True).to(DEVICE)\n",
    "context = get_python_context()\n",
    "dataset = datasets.load_dataset(\"bigcode/the-stack-smol-xl\", data_dir=\"data/python\")[\"train\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:24:14.245028Z",
     "start_time": "2023-08-21T16:23:52.809193Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " += 1\n",
      "\n",
      "  def dec(self):\n",
      "    self.count -= 1\n",
      "\n",
      "  def get(self):\n",
      "    return self.count\n",
      "\n",
      "c = Counter()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "transformers.set_seed(0)\n",
    "\n",
    "prefix_text = \"\"\"\n",
    "class Counter():\n",
    "  def __init__():\n",
    "    self.count = 0\n",
    "\n",
    "  def inc(self):\n",
    "    self.count\"\"\"\n",
    "\n",
    "suffix_text = \"\"\"  1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "middle_text = unconstrained_generation(tokenizer=tokenizer,\n",
    "                                       model=model,\n",
    "                                       prefix_text=prefix_text,\n",
    "                                       suffix_text=suffix_text,\n",
    "                                       beam_size=BEAM_SIZE,\n",
    "                                       max_new_tokens=MAX_GENERATION_LENGTH,\n",
    "                                       device=DEVICE)\n",
    "\n",
    "print(middle_text)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:24:19.602518Z",
     "start_time": "2023-08-21T16:24:14.240570Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \u001B[41m\u001B[30m+\u001B[0m\u001B[0m\u001B[42m\u001B[30m=\u001B[0m\u001B[0m\u001B[43m\u001B[30m \u001B[0m\u001B[0m1\u001B[44m\u001B[30m\n",
      "\u001B[0m\u001B[0m\u001B[45m\u001B[30m\n",
      "\u001B[0m\u001B[0m \u001B[46m\u001B[30m \u001B[0m\u001B[0mdef dec(self)\u001B[47m\u001B[30m:\u001B[0m\u001B[0m\n",
      "\u001B[40m\u001B[37m \u001B[0m\u001B[0m\u001B[41m\u001B[30m \u001B[0m\u001B[0m\u001B[42m\u001B[30m \u001B[0m\u001B[0m\u001B[43m\u001B[30m \u001B[0m\u001B[0mself.count \u001B[44m\u001B[30m-\u001B[0m\u001B[0m\u001B[45m\u001B[30m=\u001B[0m\u001B[0m\u001B[46m\u001B[30m \u001B[0m\u001B[0m1\u001B[47m\u001B[30m\n",
      "\u001B[0m\u001B[0m\u001B[40m\u001B[37m\n",
      "\u001B[0m\u001B[0m \u001B[41m\u001B[30m \u001B[0m\u001B[0mdef get(self)\u001B[42m\u001B[30m:\u001B[0m\u001B[0m\n",
      "\u001B[43m\u001B[30m \u001B[0m\u001B[0m\u001B[44m\u001B[30m \u001B[0m\u001B[0m\u001B[45m\u001B[30m \u001B[0m\u001B[0m\u001B[46m\u001B[30m \u001B[0m\u001B[0mretur\u001B[47m\u001B[30mn\u001B[0m\u001B[0m\u001B[40m\u001B[37m \u001B[0m\u001B[0mself.count\u001B[41m\u001B[30m\n",
      "\u001B[0m\u001B[0m\u001B[42m\u001B[30m\n",
      "\u001B[0m\u001B[0mc \u001B[43m\u001B[30m=\u001B[0m\u001B[0m\u001B[44m\u001B[30m \u001B[0m\u001B[0mCounter()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c.inc()\n",
      "c\n",
      "Scores:\n",
      "\u001B[41m\u001B[30m +\u001B[0m\u001B[0m : -1.367\n",
      "\u001B[42m\u001B[30m=\u001B[0m\u001B[0m : -1.367\n",
      "\u001B[43m\u001B[30m \u001B[0m\u001B[0m : -2.24\n",
      "\u001B[44m\u001B[30m1\n",
      "\u001B[0m\u001B[0m : -2.542\n",
      "\u001B[45m\u001B[30m\n",
      "\u001B[0m\u001B[0m : -2.542\n",
      "\u001B[46m\u001B[30m  \u001B[0m\u001B[0m : -2.239\n",
      "\u001B[47m\u001B[30mdef dec(self):\u001B[0m\u001B[0m : -1.808\n",
      "\u001B[40m\u001B[37m\n",
      " \u001B[0m\u001B[0m : -1.354\n",
      "\u001B[41m\u001B[30m \u001B[0m\u001B[0m : -1.354\n",
      "\u001B[42m\u001B[30m \u001B[0m\u001B[0m : -1.354\n",
      "\u001B[43m\u001B[30m \u001B[0m\u001B[0m : -1.522\n",
      "\u001B[44m\u001B[30mself.count -\u001B[0m\u001B[0m : -0.2746\n",
      "\u001B[45m\u001B[30m=\u001B[0m\u001B[0m : -0.2746\n",
      "\u001B[46m\u001B[30m \u001B[0m\u001B[0m : -0.5225\n",
      "\u001B[47m\u001B[30m1\n",
      "\u001B[0m\u001B[0m : -0.7122\n",
      "\u001B[40m\u001B[37m\n",
      "\u001B[0m\u001B[0m : -0.7122\n",
      "\u001B[41m\u001B[30m  \u001B[0m\u001B[0m : -0.7935\n",
      "\u001B[42m\u001B[30mdef get(self):\u001B[0m\u001B[0m : -0.8035\n",
      "\u001B[43m\u001B[30m\n",
      " \u001B[0m\u001B[0m : -0.7087\n",
      "\u001B[44m\u001B[30m \u001B[0m\u001B[0m : -0.7087\n",
      "\u001B[45m\u001B[30m \u001B[0m\u001B[0m : -0.7087\n",
      "\u001B[46m\u001B[30m \u001B[0m\u001B[0m : -0.4207\n",
      "\u001B[47m\u001B[30mreturn\u001B[0m\u001B[0m : -0.4207\n",
      "\u001B[40m\u001B[37m \u001B[0m\u001B[0m : -0.5728\n",
      "\u001B[41m\u001B[30mself.count\n",
      "\u001B[0m\u001B[0m : -0.4075\n",
      "\u001B[42m\u001B[30m\n",
      "\u001B[0m\u001B[0m : -0.5228\n",
      "\u001B[43m\u001B[30mc =\u001B[0m\u001B[0m : -0.5096\n",
      "\u001B[44m\u001B[30m \u001B[0m\u001B[0m : -0.5503\n",
      " += 1\n",
      "\n",
      "  def dec(self):\n",
      "    self.count -=\n"
     ]
    }
   ],
   "source": [
    "transformers.set_seed(0)\n",
    "middle_text, _ = prefix_suffix_constrained_generation(\n",
    "    tokenizer=tokenizer, model=model, context=context, prefix_text=prefix_text,\n",
    "    suffix_text=suffix_text, beam_size=BEAM_SIZE, max_generation_length=MAX_GENERATION_LENGTH, device=DEVICE,\n",
    "    debug=True#\"filtered\"\n",
    ")\n",
    "\n",
    "print(middle_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:24:32.643166Z",
     "start_time": "2023-08-21T16:24:19.600641Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Increments the counter\n",
      "    '\n"
     ]
    }
   ],
   "source": [
    "transformers.set_seed(0)\n",
    "\n",
    "prefix_text = \"\"\"\n",
    "class Counter():\n",
    "  def __init__():\n",
    "    self.count = 0\n",
    "\n",
    "  def inc(self):\n",
    "    '''\"\"\"\n",
    "\n",
    "suffix_text = \"\"\"''\n",
    "    self.count += 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "middle_text = unconstrained_generation(tokenizer=tokenizer,\n",
    "                                       model=model,\n",
    "                                       prefix_text=prefix_text,\n",
    "                                       suffix_text=suffix_text,\n",
    "                                       beam_size=BEAM_SIZE,\n",
    "                                       max_new_tokens=MAX_GENERATION_LENGTH,\n",
    "                                       device=DEVICE)\n",
    "\n",
    "print(middle_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:24:32.831737Z",
     "start_time": "2023-08-21T16:24:32.645237Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def show_example(data_idx: int, cut_idx: int, also_unconstrained: bool = False):\n",
    "    chosen_dataset_content = dataset[data_idx][\"content\"]\n",
    "    random.seed(hash((data_idx, cut_idx)) % (2 ** 32))\n",
    "    prefix, middle, suffix = cut_text_random(chosen_dataset_content, 0, .9, .2)\n",
    "    suffix = suffix + \"\\n\"\n",
    "    \n",
    "    pre_input_ids, pre_attention_mask = tokenizer_int64(tokenizer, prefix)\n",
    "    post_input_ids, post_attention_mask = tokenizer_int64(tokenizer, suffix)\n",
    "\n",
    "    input_ids, attention_mask = create_balanced_context(\n",
    "        pre_input_ids=pre_input_ids, pre_attention_mask=pre_attention_mask,\n",
    "        post_input_ids=post_input_ids, post_attention_mask=post_attention_mask,\n",
    "        tokenizer=tokenizer, max_generation_length=500, device=\"cuda:0\"\n",
    "    )\n",
    "\n",
    "    new_output_text_constrained, full_constrained = do_prefix_suffix_constrained_generation(\n",
    "        tokenizer=tokenizer, model=model, context=context,\n",
    "        input_ids=input_ids, attention_mask=attention_mask,\n",
    "        prefix_text=prefix, suffix_text=suffix,\n",
    "        pre_input_ids=pre_input_ids, post_input_ids=post_input_ids,\n",
    "        beam_size=1, max_generation_length=500,\n",
    "        debug=False\n",
    "    )\n",
    "\n",
    "    if new_output_text_constrained is not None:\n",
    "        print(prefix + bg.boldgreen(fg.black(new_output_text_constrained)) + suffix)\n",
    "    else:\n",
    "        print(prefix + bg.boldcyan(fg.black(full_constrained)) + suffix)\n",
    "\n",
    "    if also_unconstrained:\n",
    "        print(\"\\n\" + bg.boldmagenta(\"----------------\") + \"\\n\")\n",
    "        outputs_unconstrained = model.generate(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                                                max_new_tokens=500,\n",
    "                                                num_beams=1, num_return_sequences=1,\n",
    "                                                early_stopping=True)\n",
    "\n",
    "        len_input_tokens = input_ids.shape[1]\n",
    "\n",
    "        new_output_tokens_unconstrained = outputs_unconstrained[0][len_input_tokens:]\n",
    "        new_output_text_unconstrained = tokenizer.decode(new_output_tokens_unconstrained, skip_special_tokens=True,\n",
    "                                                     clean_up_tokenization_spaces=False)\n",
    "\n",
    "        if new_output_text_unconstrained is not None:\n",
    "            print(prefix + bg.boldred(fg.black(new_output_text_unconstrained)) + suffix)\n",
    "            \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-21T16:24:32.851071Z",
     "start_time": "2023-08-21T16:24:32.831635Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_example(1470, 5, True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_example(8440, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_example(1804, 4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_example(8551, 8)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_example(7396, 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_example(8, 5)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
